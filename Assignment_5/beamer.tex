\documentclass{beamer}
\usepackage{listings}
\lstset{
%language=C,
frame=single, 
breaklines=true,
columns=fullflexible
}
\usepackage{blkarray}
\usepackage{subcaption}
\usepackage{url}
\usepackage{optidef}
\usepackage{tikz}
\usepackage{tkz-euclide} % loads  TikZ and tkz-base
%\usetkzobj{all}
\usetikzlibrary{calc,math}
\usepackage{float}
\newcommand\norm[1]{\left\lVert#1\right\rVert}
\renewcommand{\vec}[1]{\mathbf{#1}}
\usepackage[export]{adjustbox}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{tikz}
\usepackage{hyperref}
\usepackage{bm}
\hypersetup{
    colorlinks = true,
    linkbordercolor = {white},
    linkcolor={red},
    citecolor={green},
    filecolor={blue},
	menucolor={red},
	runcolor={cyan},
	urlcolor={blue},
	breaklinks=true
}
\usetikzlibrary{automata, positioning}
\usetheme{Boadilla}
\providecommand{\pr}[1]{\ensuremath{\Pr\left(#1\right)}}
\providecommand{\mbf}{\mathbf}
\providecommand{\qfunc}[1]{\ensuremath{Q\left(#1\right)}}
\providecommand{\sbrak}[1]{\ensuremath{{}\left[#1\right]}}
\providecommand{\lsbrak}[1]{\ensuremath{{}\left[#1\right.}}
\providecommand{\rsbrak}[1]{\ensuremath{{}\left.#1\right]}}
\providecommand{\brak}[1]{\ensuremath{\left(#1\right)}}
\providecommand{\lbrak}[1]{\ensuremath{\left(#1\right.}}
\providecommand{\rbrak}[1]{\ensuremath{\left.#1\right)}}
\providecommand{\cbrak}[1]{\ensuremath{\left\{#1\right\}}}
\providecommand{\lcbrak}[1]{\ensuremath{\left\{#1\right.}}
\providecommand{\rcbrak}[1]{\ensuremath{\left.#1\right\}}}
\providecommand{\abs}[1]{\vert#1\vert}
\newcommand{\comb}[2]{{}^{#1}\mathrm{C}_{#2}}

\title{Presentation on CSIR UGC NET (June 2015) Q. 106}
\author{Jatin Tarachandani}
\date{CS20BTECH11021}
\begin{document}

\begin{frame}
\titlepage
\end{frame}

\begin{frame}{Some Definitions}
\begin{definition}
The pmf for a binomial distribution with parameters $n$ and $p$ is
\begin{align}
    \pr{X=x;n, p}=\comb{n}{x}p^{x}\brak{1-p}^{n-x}
\end{align}
\end{definition}
\begin{definition}
The pmf for a Poisson distribution with parameter $\lambda$ is:
\begin{align}
    \pr{Y=y; \lambda}=\frac{\lambda^y}{y!} e^{-\lambda}
\end{align}
\end{definition}


\end{frame}
\begin{frame}{Unbiased Estimators}

\begin{block}{Definition}
Suppose we have an estimator $T(X, Y)$, acting on a set of 2 RVs $X, Y$; which estimates a parameter $\theta$, then if
\begin{equation}
    E\brak{T(X, Y)}=\theta
\end{equation}
the estimator is unbiased.
\end{block}
    
\end{frame}
\begin{frame}{Problem statement}
\begin{block}{
}
Let $X$, $Y$, have the joint discrete distribution such that $X|Y=y \sim$ Binomial($y$, 0.5) and $Y\sim$ Poisson($\lambda$), $\lambda>0$, where $\lambda$ is an unknown parameter. Let $T=T(X, Y)$ be any unbiased estimator of $\lambda$. Then
\begin{enumerate}
    \item  $Var(T) \leq Var(Y)  \text{ for all } \lambda$
    \item $Var(T) \geq Var(Y) \text{ for all } \lambda$
    \item $Var(T) \geq \lambda \text{ for all } \lambda$
    \item $Var(T) = Var(Y) \text{ for all } \lambda$
\end{enumerate}

\end{block}
\end{frame}
\begin{frame}{Solution}
We know that since Y has a Poisson distribution with parameter $\lambda$, 
\begin{align}
    Var(Y)=\lambda \label{Var=lam}
\end{align}
Since $X, Y$ are discrete, we define $ p_{XY}\brak{X, Y}$ as the joint discrete distribution of $X$ and $Y$.
From Bayes Theorem,
\begin{align}
    p_{XY}\brak{X, Y}&=\pr{X=x|Y=y} \pr{Y=y}  \\
    &= \comb{y}{x} \frac{1}{2^y} \frac{\lambda^y}{y!} e^{- \lambda}\label{joint pmf}
\end{align} 
    
\end{frame}
\begin{frame}{Cramer Rao lower bound}
\begin{definition} 
If $T(X, Y)$ is an unbiased estimator of a parameter $\lambda$, the Cramer-Rao bound states that:
\begin{align}
    Var\brak{T\brak{X,Y}}\geq -\frac{1}{E\brak{\frac{\partial^2 \ln(p_{XY}\brak{X, Y}))}{\partial\lambda^2}}} \label{def CRB}
\end{align}
\end{definition}
\begin{block}{}
Since $\lambda$ is a continuous parameter, we can apply this inequality to the logarithm of the joint discrete distribution seen in \eqref{joint pmf}.

\end{block}
\end{frame}
\begin{frame}{}
\begin{lemma}
\begin{equation}
    \frac{\partial^2 \ln(p_{XY}\brak{X, Y})}{\partial\lambda^2}=-\frac{Y}{\lambda^2} \label{partial}
\end{equation}
\end{lemma}
\begin{proof}
\begin{align}
p_{XY}\brak{X, Y}&= \comb{Y}{X} \frac{1}{2^Y} \frac{\lambda^Y}{Y!}e^{- \lambda}\\
\frac{\partial^2 \ln(p_{XY}\brak{X, Y})}{\partial\lambda^2}&=\frac{\partial^2\brak{ \splitfrac{\ln{\comb{Y}{X}}-Y\ln{2^Y}}{+Y\ln{\lambda}-\ln{Y!}-\lambda}}}{\partial\lambda^2}\\
&=\frac{\partial\brak{ \frac{Y}{\lambda}-1}}{\partial\lambda}\\
&=-\frac{Y}{\lambda^2}
\end{align}
which is the required result.
\end{proof}
    
\end{frame}
\begin{frame}{}
From using $\eqref{def CRB}$ on $T(X,Y)$,
\begin{align}
    Var(T(X, Y))&\geq -\frac{1}{E\brak{\frac{\partial^2 \ln(p_{XY}\brak{X, Y})}{\partial\lambda^2}}}
\end{align}
From $\eqref{partial}$,
\begin{align}
     Var(T(X, Y))&\geq-\frac{1}{E\brak{-\frac{Y}{\lambda^2}}}\\
    &\geq\frac{\lambda^2}{E\brak{Y}}\\
    Var(T(X, Y))&\geq \lambda \label{CramerRao}
\end{align}
because the expectation value of a Poisson R.V with parameter $\lambda$ is $\lambda$.
    
\end{frame}
\begin{frame}{}
    The correct options are options (2) and (3), since by \eqref{CramerRao}, we see that 
\begin{align*}
Var(T) \geq \lambda=Var(Y)
\end{align*}
(from \eqref{Var=lam}). (1) and (4) do not hold for all $\lambda$. 
    
\end{frame}

\end{document}